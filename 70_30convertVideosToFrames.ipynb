{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "olympic-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "filename = 'Dataset70_30' # OR \"Dataset70_30\"( to run second time with 'Dataset80_20')\n",
    "\n",
    "dataset_path =filename +\"/train\"      # os.path.join(filename, 'train')\n",
    "#dataset_path_frames_dir = filename+\"/train_frames\"\n",
    "\n",
    "\n",
    "#os.makedirs(dataset_path_frames_dir)\n",
    "\n",
    "\n",
    "# {\"American Football\", \"Animation\", \"Baseball\", \"Basketball\",\n",
    "#  \"Cooking and food recipes\", \"Golf\", \"Graffiti Art\", \"Hair Style\",\n",
    "#  \"Ice Hockey\", \"Judo\", \"Soccer\", \"Speeches and Lectures-Talks\",\n",
    "#  \"Swimming(in Pool)\", \"Tennis\", \"Underwater-Ocean life\",\n",
    "#  \"Volleyball\"}\n",
    "\n",
    "\n",
    "classes = [\"American Football\", \"Animation\", \"Baseball\", \"Basketball\",\n",
    " \"Cooking and food recipes\", \"Golf\", \"Graffiti Art\", \"Hair Style\",\n",
    " \"Ice Hockey\", \"Judo\", \"Soccer\", \"Speeches and Lectures-Talks\",\n",
    " \"Swimming(in Pool)\", \"Tennis\", \"Underwater-Ocean life\",\n",
    " \"Volleyball\"]\n",
    "\n",
    "seq_size = 2040\n",
    "# dataset_path_frames_jenre_dir = dataset_path_frames_dir+\"/Cooking\"\n",
    "\n",
    "# os.makedirs(dataset_path_frames_jenre_dir)\n",
    "\n",
    "# dataset_path_video_jenre =dataset_path+\"/Cooking and food recipes\"\n",
    "# print(dataset_path)\n",
    "\n",
    "# filename = 'partial_dataset' # OR \"Dataset70_30\"( to run second time with 'Dataset80_20')\n",
    "\n",
    "# dataset_path =filename +\"/train\"     # os.path.join(filename, 'train')\n",
    "# dataset_path_frames_dir = filename+\"_frames\"\n",
    "\n",
    "\n",
    "# os.makedirs(dataset_path_frames_dir)\n",
    "# \"\"\"\n",
    "# test_path =filename +\"/test\"      # os.path.join(filename, 'train')\n",
    "# test_path_frames_dir = filename+\"/test_frames\"\n",
    "\n",
    "\n",
    "# os.makedirs(test_path_frames_dir)\n",
    "# \"\"\"\n",
    "# classes = [\"Animation\", \"Cooking and food recipes\"]\n",
    "\n",
    "\n",
    "# dataset_path_frames_jenre_dir = dataset_path_frames_dir+\"/Cooking\"\n",
    "\n",
    "# os.makedirs(dataset_path_frames_jenre_dir)\n",
    "\n",
    "# dataset_path_video_jenre =dataset_path+\"/Cooking and food recipes\"\n",
    "# print(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bright-palace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min num of frames per video: \n",
      "2040\n",
      "num of problematic videos: \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#creat frames from train:\n",
    "\n",
    "#data_dir = dataset_path\n",
    "#Desktop/folder to split dataset videogenre try/Dataset70_30/train/Animation\n",
    "count_problematic_vid = 0\n",
    "min_frames_per_vide=2040\n",
    "for jenre in classes:\n",
    "    #dataset_path_frames_jenre_dir = dataset_path_frames_dir+\"/\"+jenre\n",
    "\n",
    "    #os.makedirs(dataset_path_frames_jenre_dir)\n",
    "\n",
    "    dataset_path_video_jenre = dataset_path+\"/\"+jenre\n",
    "    #print(dataset_path)\n",
    "\n",
    "    listing = os.listdir(dataset_path_video_jenre)\n",
    "    #print(listing)\n",
    "    #listing = [inst for inst in listing if not inst.startswith(\".\")]\n",
    "    #print(listing)\n",
    "    \n",
    "    for file in listing:\n",
    "        #filenameeee= Path(file).stem\n",
    "        #print(filenameeee)\n",
    "        our_video = dataset_path_video_jenre +\"/\"+file\n",
    "        #print(our_video)\n",
    "        cap = cv2.VideoCapture(our_video)\n",
    "        #print(video.isOpened())\n",
    "        #framerate = video.get(5)\n",
    "        #os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + str(int(count)))\n",
    "        #filenamenotype= Path(file).stem\n",
    "        #print(filenamenotype)\n",
    "        #os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + filenamenotype)\n",
    "        \n",
    "        if (cap.isOpened()):\n",
    "            #frameId = video.get(1)\n",
    "            #success,image = video.read()        \n",
    "            numberofframes = cap.get(cv2.CAP_PROP_FRAME_COUNT)  # frames size in video\n",
    "            if(seq_size > numberofframes):\n",
    "                count_problematic_vid= count_problematic_vid+1\n",
    "                print(\"problematic video: \")\n",
    "                print(our_video)\n",
    "                print(\"num of frames: \")\n",
    "                print(numberofframes)\n",
    "                if( min_frames_per_vide > numberofframes):\n",
    "                    min_frames_per_vide=numberofframes\n",
    "                \n",
    "            \n",
    "\n",
    "        else:\n",
    "            print(\"cap could not open - in video:\\n\")\n",
    "            print(our_video)\n",
    "            exit()\n",
    "        cap.release()\n",
    "        #print('done')\n",
    "\n",
    "print(\"min num of frames per video: \")\n",
    "print(min_frames_per_vide)\n",
    "print(\"num of problematic videos: \")\n",
    "print(count_problematic_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acknowledged-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "filename = 'Dataset70_30' # OR \"Dataset70_30\"( to run second time with 'Dataset80_20')\n",
    "\n",
    "dataset_path =filename +\"/test\"      # os.path.join(filename, 'train')\n",
    "#dataset_path_frames_dir = filename+\"/train_frames\"\n",
    "\n",
    "\n",
    "#os.makedirs(dataset_path_frames_dir)\n",
    "\n",
    "\n",
    "# {\"American Football\", \"Animation\", \"Baseball\", \"Basketball\",\n",
    "#  \"Cooking and food recipes\", \"Golf\", \"Graffiti Art\", \"Hair Style\",\n",
    "#  \"Ice Hockey\", \"Judo\", \"Soccer\", \"Speeches and Lectures-Talks\",\n",
    "#  \"Swimming(in Pool)\", \"Tennis\", \"Underwater-Ocean life\",\n",
    "#  \"Volleyball\"}\n",
    "\n",
    "\n",
    "classes = [\"American Football\", \"Animation\", \"Baseball\", \"Basketball\",\n",
    " \"Cooking and food recipes\", \"Golf\", \"Graffiti Art\", \"Hair Style\",\n",
    " \"Ice Hockey\", \"Judo\", \"Soccer\", \"Speeches and Lectures-Talks\",\n",
    " \"Swimming(in Pool)\", \"Tennis\", \"Underwater-Ocean life\",\n",
    " \"Volleyball\"]\n",
    "\n",
    "seq_size = 2040\n",
    "# dataset_path_frames_jenre_dir = dataset_path_frames_dir+\"/Cooking\"\n",
    "\n",
    "# os.makedirs(dataset_path_frames_jenre_dir)\n",
    "\n",
    "# dataset_path_video_jenre =dataset_path+\"/Cooking and food recipes\"\n",
    "# print(dataset_path)\n",
    "\n",
    "# filename = 'partial_dataset' # OR \"Dataset70_30\"( to run second time with 'Dataset80_20')\n",
    "\n",
    "# dataset_path =filename +\"/train\"     # os.path.join(filename, 'train')\n",
    "# dataset_path_frames_dir = filename+\"_frames\"\n",
    "\n",
    "\n",
    "# os.makedirs(dataset_path_frames_dir)\n",
    "# \"\"\"\n",
    "# test_path =filename +\"/test\"      # os.path.join(filename, 'train')\n",
    "# test_path_frames_dir = filename+\"/test_frames\"\n",
    "\n",
    "\n",
    "# os.makedirs(test_path_frames_dir)\n",
    "# \"\"\"\n",
    "# classes = [\"Animation\", \"Cooking and food recipes\"]\n",
    "\n",
    "\n",
    "# dataset_path_frames_jenre_dir = dataset_path_frames_dir+\"/Cooking\"\n",
    "\n",
    "# os.makedirs(dataset_path_frames_jenre_dir)\n",
    "\n",
    "# dataset_path_video_jenre =dataset_path+\"/Cooking and food recipes\"\n",
    "# print(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accepted-catalyst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min num of frames per video: \n",
      "2040\n",
      "num of problematic videos: \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#creat frames from train:\n",
    "\n",
    "#data_dir = dataset_path\n",
    "#Desktop/folder to split dataset videogenre try/Dataset70_30/train/Animation\n",
    "count_problematic_vid = 0\n",
    "min_frames_per_vide=2040\n",
    "for jenre in classes:\n",
    "    #dataset_path_frames_jenre_dir = dataset_path_frames_dir+\"/\"+jenre\n",
    "\n",
    "    #os.makedirs(dataset_path_frames_jenre_dir)\n",
    "\n",
    "    dataset_path_video_jenre = dataset_path+\"/\"+jenre\n",
    "    #print(dataset_path)\n",
    "\n",
    "    listing = os.listdir(dataset_path_video_jenre)\n",
    "    #print(listing)\n",
    "    #listing = [inst for inst in listing if not inst.startswith(\".\")]\n",
    "    #print(listing)\n",
    "    \n",
    "    for file in listing:\n",
    "        #filenameeee= Path(file).stem\n",
    "        #print(filenameeee)\n",
    "        our_video = dataset_path_video_jenre +\"/\"+file\n",
    "        #print(our_video)\n",
    "        cap = cv2.VideoCapture(our_video)\n",
    "        #print(video.isOpened())\n",
    "        #framerate = video.get(5)\n",
    "        #os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + str(int(count)))\n",
    "        #filenamenotype= Path(file).stem\n",
    "        #print(filenamenotype)\n",
    "        #os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + filenamenotype)\n",
    "        \n",
    "        if (cap.isOpened()):\n",
    "            #frameId = video.get(1)\n",
    "            #success,image = video.read()        \n",
    "            numberofframes = cap.get(cv2.CAP_PROP_FRAME_COUNT)  # frames size in video\n",
    "            if(seq_size > numberofframes):\n",
    "                count_problematic_vid= count_problematic_vid+1\n",
    "                print(\"problematic video: \")\n",
    "                print(our_video)\n",
    "                print(\"num of frames: \")\n",
    "                print(numberofframes)\n",
    "                if( min_frames_per_vide > numberofframes):\n",
    "                    min_frames_per_vide=numberofframes\n",
    "                \n",
    "            \n",
    "\n",
    "        else:\n",
    "            print(\"cap could not open - in video:\\n\")\n",
    "            print(our_video)\n",
    "            exit()\n",
    "        cap.release()\n",
    "        #print('done')\n",
    "\n",
    "print(\"min num of frames per video: \")\n",
    "print(min_frames_per_vide)\n",
    "print(\"num of problematic videos: \")\n",
    "print(count_problematic_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-employee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wrapped-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #creat frames from test:\n",
    "\n",
    "\n",
    "# #data_dir = dataset_path\n",
    "# #Desktop/folder to split dataset videogenre try/Dataset70_30/train/Animation\n",
    "# for jenre in classes:\n",
    "#     dataset_path_frames_jenre_dir = dataset_path_frames_dir+\"/\"+jenre\n",
    "\n",
    "#     os.makedirs(dataset_path_frames_jenre_dir)\n",
    "\n",
    "#     dataset_path_video_jenre = dataset_path+\"/\"+jenre\n",
    "#     #print(dataset_path)\n",
    "\n",
    "#     listing = os.listdir(dataset_path_video_jenre)\n",
    "#     #print(listing)\n",
    "#     #listing = [inst for inst in listing if not inst.startswith(\".\")]\n",
    "#     #print(listing)\n",
    "#     seq_size = 30\n",
    "#     for file in listing:\n",
    "#         #filenameeee= Path(file).stem\n",
    "#         #print(filenameeee)\n",
    "#         our_video = dataset_path_video_jenre +\"/\"+file\n",
    "#         #print(our_video)\n",
    "#         cap = cv2.VideoCapture(our_video)\n",
    "#         #print(video.isOpened())\n",
    "#         #framerate = video.get(5)\n",
    "#         #os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + str(int(count)))\n",
    "#         filenamenotype= Path(file).stem\n",
    "#         #print(filenamenotype)\n",
    "#         os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + filenamenotype)\n",
    "#         count = 0\n",
    "#         if (cap.isOpened()):\n",
    "#             #frameId = video.get(1)\n",
    "#             #success,image = video.read()        \n",
    "#             numberofframes = cap.get(cv2.CAP_PROP_FRAME_COUNT)  # frames size in video\n",
    "\n",
    "#             jumping_frames = int(np.floor(numberofframes / seq_size) ) # need to take frame after this number of times\n",
    "#             #frame_index_array = []\n",
    "#             for i in range(0, seq_size):  # data size is the video size, check if start from 0 or 1 and end with size or size+1\n",
    "#                 # need to add index of frame  that devide with out reminder in self.seq_size from the specific video\n",
    "#                 #cap.set(cv2.CAP_PROP_POS_FRAMES,i*jumping_frames)\n",
    "#                 #changed to dumpy run over jumping frames, to prevent error accurs using cap.set in for loop\n",
    "#                 for j in range(0,jumping_frames-1):\n",
    "#                     ret, frame = cap.read()\n",
    "#                 ret, frame = cap.read()\n",
    "#                 if ret == True:\n",
    "#                     #resizearr = np.resize(frame, (3, 180, 220))\n",
    "#                     #tensor[i] = torch.from_numpy(resizearr)\n",
    "#                     filename = dataset_path_frames_jenre_dir + \"/video_\" + filenamenotype + \"/frame_\" + str(int(count)) + \".jpg\"\n",
    "#                     #print(filename)\n",
    "#                     cv2.imwrite(filename,frame)\n",
    "#                     count = count+1\n",
    "#                 else:\n",
    "#                     print(\"frame didnt extracted well or finished if shows uup try to delete this printing, in video:\\n\")\n",
    "#                     print(our_video)\n",
    "#                     break\n",
    "\n",
    "#         else:\n",
    "#             print(\"cap could not open - in video:\\n\")\n",
    "#             print(our_video)\n",
    "#             exit()\n",
    "#         cap.release()\n",
    "#         #print('done')\n",
    "\n",
    "# #         os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + str(int(count)))\n",
    "# #         if( image is not None ):\n",
    "# #             image=cv2.resize(image,(224,224), interpolation = cv2.INTER_AREA)\n",
    "# #         if (success is not True):\n",
    "# #             break\n",
    "# #         if (frameId % math.floor(framerate) == 0):\n",
    "# #             filename = dataset_path_frames_jenre_dir + \"/video_\" + str(int(count)) + \"/image_\" + str(int(frameId / math.floor(framerate))+1) + \".jpg\"\n",
    "# #             print(filename)\n",
    "# #             cv2.imwrite(filename,image)\n",
    "# #     video.release()\n",
    "# #     print('done')\n",
    "# #     count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-vault",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
