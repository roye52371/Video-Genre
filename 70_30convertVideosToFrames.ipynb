{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "coupled-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "filename = 'Dataset70_30' # OR \"Dataset70_30\"( to run second time with 'Dataset80_20')\n",
    "\n",
    "dataset_path =filename +\"/train\"      # os.path.join(filename, 'train')\n",
    "dataset_path_frames_dir = filename+\"/train_frames\"\n",
    "\n",
    "\n",
    "os.makedirs(dataset_path_frames_dir)\n",
    "\n",
    "\n",
    "# {\"American Football\", \"Animation\", \"Baseball\", \"Basketball\",\n",
    "#  \"Cooking and food recipes\", \"Golf\", \"Graffiti Art\", \"Hair Style\",\n",
    "#  \"Ice Hockey\", \"Judo\", \"Soccer\", \"Speeches and Lectures-Talks\",\n",
    "#  \"Swimming(in Pool)\", \"Tennis\", \"Underwater-Ocean life\",\n",
    "#  \"Volleyball\"}\n",
    "\n",
    "\n",
    "classes = [\"American Football\", \"Animation\", \"Baseball\", \"Basketball\",\n",
    " \"Cooking and food recipes\", \"Golf\", \"Graffiti Art\", \"Hair Style\",\n",
    " \"Ice Hockey\", \"Judo\", \"Soccer\", \"Speeches and Lectures-Talks\",\n",
    " \"Swimming(in Pool)\", \"Tennis\", \"Underwater-Ocean life\",\n",
    " \"Volleyball\"]\n",
    "\n",
    "\n",
    "# dataset_path_frames_jenre_dir = dataset_path_frames_dir+\"/Cooking\"\n",
    "\n",
    "# os.makedirs(dataset_path_frames_jenre_dir)\n",
    "\n",
    "# dataset_path_video_jenre =dataset_path+\"/Cooking and food recipes\"\n",
    "# print(dataset_path)\n",
    "\n",
    "# filename = 'partial_dataset' # OR \"Dataset70_30\"( to run second time with 'Dataset80_20')\n",
    "\n",
    "# dataset_path =filename +\"/train\"     # os.path.join(filename, 'train')\n",
    "# dataset_path_frames_dir = filename+\"_frames\"\n",
    "\n",
    "\n",
    "# os.makedirs(dataset_path_frames_dir)\n",
    "# \"\"\"\n",
    "# test_path =filename +\"/test\"      # os.path.join(filename, 'train')\n",
    "# test_path_frames_dir = filename+\"/test_frames\"\n",
    "\n",
    "\n",
    "# os.makedirs(test_path_frames_dir)\n",
    "# \"\"\"\n",
    "# classes = [\"Animation\", \"Cooking and food recipes\"]\n",
    "\n",
    "\n",
    "# dataset_path_frames_jenre_dir = dataset_path_frames_dir+\"/Cooking\"\n",
    "\n",
    "# os.makedirs(dataset_path_frames_jenre_dir)\n",
    "\n",
    "# dataset_path_video_jenre =dataset_path+\"/Cooking and food recipes\"\n",
    "# print(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "authorized-notice",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat frames from train:\n",
    "\n",
    "#data_dir = dataset_path\n",
    "#Desktop/folder to split dataset videogenre try/Dataset70_30/train/Animation\n",
    "for jenre in classes:\n",
    "    dataset_path_frames_jenre_dir = dataset_path_frames_dir+\"/\"+jenre\n",
    "\n",
    "    os.makedirs(dataset_path_frames_jenre_dir)\n",
    "\n",
    "    dataset_path_video_jenre = dataset_path+\"/\"+jenre\n",
    "    #print(dataset_path)\n",
    "\n",
    "    listing = os.listdir(dataset_path_video_jenre)\n",
    "    #print(listing)\n",
    "    #listing = [inst for inst in listing if not inst.startswith(\".\")]\n",
    "    #print(listing)\n",
    "    seq_size = 30\n",
    "    for file in listing:\n",
    "        #filenameeee= Path(file).stem\n",
    "        #print(filenameeee)\n",
    "        our_video = dataset_path_video_jenre +\"/\"+file\n",
    "        #print(our_video)\n",
    "        cap = cv2.VideoCapture(our_video)\n",
    "        #print(video.isOpened())\n",
    "        #framerate = video.get(5)\n",
    "        #os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + str(int(count)))\n",
    "        filenamenotype= Path(file).stem\n",
    "        #print(filenamenotype)\n",
    "        os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + filenamenotype)\n",
    "        count = 0\n",
    "        if (cap.isOpened()):\n",
    "            #frameId = video.get(1)\n",
    "            #success,image = video.read()        \n",
    "            numberofframes = cap.get(cv2.CAP_PROP_FRAME_COUNT)  # frames size in video\n",
    "\n",
    "            jumping_frames = int(np.floor(numberofframes / seq_size) ) # need to take frame after this number of times\n",
    "            #frame_index_array = []\n",
    "            for i in range(0, seq_size):  # data size is the video size, check if start from 0 or 1 and end with size or size+1\n",
    "                # need to add index of frame  that devide with out reminder in self.seq_size from the specific video\n",
    "                #cap.set(cv2.CAP_PROP_POS_FRAMES,i*jumping_frames)\n",
    "                #changed to dumpy run over jumping frames, to prevent error accurs using cap.set in for loop\n",
    "                for j in range(0,jumping_frames-1):\n",
    "                    ret, frame = cap.read()\n",
    "                ret, frame = cap.read()\n",
    "                if ret == True:\n",
    "                    #resizearr = np.resize(frame, (3, 180, 220))\n",
    "                    #tensor[i] = torch.from_numpy(resizearr)\n",
    "                    filename = dataset_path_frames_jenre_dir + \"/video_\" + filenamenotype + \"/frame_\" + str(int(count)) + \".jpg\"\n",
    "                    #print(filename)\n",
    "                    cv2.imwrite(filename,frame)\n",
    "                    count = count+1\n",
    "                else:\n",
    "                    print(\"frame didnt extracted well or finished if shows uup try to delete this printing, in video:\\n\")\n",
    "                    print(our_video)\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            print(\"cap could not open - in video:\\n\")\n",
    "            print(our_video)\n",
    "            exit()\n",
    "        cap.release()\n",
    "        #print('done')\n",
    "\n",
    "#         os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + str(int(count)))\n",
    "#         if( image is not None ):\n",
    "#             image=cv2.resize(image,(224,224), interpolation = cv2.INTER_AREA)\n",
    "#         if (success is not True):\n",
    "#             break\n",
    "#         if (frameId % math.floor(framerate) == 0):\n",
    "#             filename = dataset_path_frames_jenre_dir + \"/video_\" + str(int(count)) + \"/image_\" + str(int(frameId / math.floor(framerate))+1) + \".jpg\"\n",
    "#             print(filename)\n",
    "#             cv2.imwrite(filename,image)\n",
    "#     video.release()\n",
    "#     print('done')\n",
    "#     count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "engaging-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "filename = 'Dataset70_30' # OR \"Dataset70_30\"( to run second time with 'Dataset80_20')\n",
    "\n",
    "\n",
    "\n",
    "dataset_path =filename +\"/test\"      # os.path.join(filename, 'train')\n",
    "dataset_path_frames_dir = filename+\"/test_frames\"\n",
    "\n",
    "\n",
    "os.makedirs(dataset_path_frames_dir)\n",
    "\n",
    "# {\"American Football\", \"Animation\", \"Baseball\", \"Basketball\",\n",
    "#  \"Cooking and food recipes\", \"Golf\", \"Graffiti Art\", \"Hair Style\",\n",
    "#  \"Ice Hockey\", \"Judo\", \"Soccer\", \"Speeches and Lectures-Talks\",\n",
    "#  \"Swimming(in Pool)\", \"Tennis\", \"Underwater-Ocean life\",\n",
    "#  \"Volleyball\"}\n",
    "\n",
    "\n",
    "classes = [\"American Football\", \"Animation\", \"Baseball\", \"Basketball\",\n",
    " \"Cooking and food recipes\", \"Golf\", \"Graffiti Art\", \"Hair Style\",\n",
    " \"Ice Hockey\", \"Judo\", \"Soccer\", \"Speeches and Lectures-Talks\",\n",
    " \"Swimming(in Pool)\", \"Tennis\", \"Underwater-Ocean life\",\n",
    " \"Volleyball\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-directive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "criminal-occasions",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat frames from test:\n",
    "\n",
    "\n",
    "#data_dir = dataset_path\n",
    "#Desktop/folder to split dataset videogenre try/Dataset70_30/train/Animation\n",
    "for jenre in classes:\n",
    "    dataset_path_frames_jenre_dir = dataset_path_frames_dir+\"/\"+jenre\n",
    "\n",
    "    os.makedirs(dataset_path_frames_jenre_dir)\n",
    "\n",
    "    dataset_path_video_jenre = dataset_path+\"/\"+jenre\n",
    "    #print(dataset_path)\n",
    "\n",
    "    listing = os.listdir(dataset_path_video_jenre)\n",
    "    #print(listing)\n",
    "    #listing = [inst for inst in listing if not inst.startswith(\".\")]\n",
    "    #print(listing)\n",
    "    seq_size = 30\n",
    "    for file in listing:\n",
    "        #filenameeee= Path(file).stem\n",
    "        #print(filenameeee)\n",
    "        our_video = dataset_path_video_jenre +\"/\"+file\n",
    "        #print(our_video)\n",
    "        cap = cv2.VideoCapture(our_video)\n",
    "        #print(video.isOpened())\n",
    "        #framerate = video.get(5)\n",
    "        #os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + str(int(count)))\n",
    "        filenamenotype= Path(file).stem\n",
    "        #print(filenamenotype)\n",
    "        os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + filenamenotype)\n",
    "        count = 0\n",
    "        if (cap.isOpened()):\n",
    "            #frameId = video.get(1)\n",
    "            #success,image = video.read()        \n",
    "            numberofframes = cap.get(cv2.CAP_PROP_FRAME_COUNT)  # frames size in video\n",
    "\n",
    "            jumping_frames = int(np.floor(numberofframes / seq_size) ) # need to take frame after this number of times\n",
    "            #frame_index_array = []\n",
    "            for i in range(0, seq_size):  # data size is the video size, check if start from 0 or 1 and end with size or size+1\n",
    "                # need to add index of frame  that devide with out reminder in self.seq_size from the specific video\n",
    "                #cap.set(cv2.CAP_PROP_POS_FRAMES,i*jumping_frames)\n",
    "                #changed to dumpy run over jumping frames, to prevent error accurs using cap.set in for loop\n",
    "                for j in range(0,jumping_frames-1):\n",
    "                    ret, frame = cap.read()\n",
    "                ret, frame = cap.read()\n",
    "                if ret == True:\n",
    "                    #resizearr = np.resize(frame, (3, 180, 220))\n",
    "                    #tensor[i] = torch.from_numpy(resizearr)\n",
    "                    filename = dataset_path_frames_jenre_dir + \"/video_\" + filenamenotype + \"/frame_\" + str(int(count)) + \".jpg\"\n",
    "                    #print(filename)\n",
    "                    cv2.imwrite(filename,frame)\n",
    "                    count = count+1\n",
    "                else:\n",
    "                    print(\"frame didnt extracted well or finished if shows uup try to delete this printing, in video:\\n\")\n",
    "                    print(our_video)\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            print(\"cap could not open - in video:\\n\")\n",
    "            print(our_video)\n",
    "            exit()\n",
    "        cap.release()\n",
    "        #print('done')\n",
    "\n",
    "#         os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + str(int(count)))\n",
    "#         if( image is not None ):\n",
    "#             image=cv2.resize(image,(224,224), interpolation = cv2.INTER_AREA)\n",
    "#         if (success is not True):\n",
    "#             break\n",
    "#         if (frameId % math.floor(framerate) == 0):\n",
    "#             filename = dataset_path_frames_jenre_dir + \"/video_\" + str(int(count)) + \"/image_\" + str(int(frameId / math.floor(framerate))+1) + \".jpg\"\n",
    "#             print(filename)\n",
    "#             cv2.imwrite(filename,image)\n",
    "#     video.release()\n",
    "#     print('done')\n",
    "#     count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-final",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
