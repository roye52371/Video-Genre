{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "federal-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "filename = 'Dataset70_30' # OR \"Dataset70_30\"( to run second time with 'Dataset80_20')\n",
    "\n",
    "dataset_path =filename +\"/train\"      # os.path.join(filename, 'train')\n",
    "#dataset_path_frames_dir = filename+\"/train_frames\"\n",
    "\n",
    "\n",
    "#os.makedirs(dataset_path_frames_dir)\n",
    "\n",
    "\n",
    "# {\"American Football\", \"Animation\", \"Baseball\", \"Basketball\",\n",
    "#  \"Cooking and food recipes\", \"Golf\", \"Graffiti Art\", \"Hair Style\",\n",
    "#  \"Ice Hockey\", \"Judo\", \"Soccer\", \"Speeches and Lectures-Talks\",\n",
    "#  \"Swimming(in Pool)\", \"Tennis\", \"Underwater-Ocean life\",\n",
    "#  \"Volleyball\"}\n",
    "\n",
    "\n",
    "classes = [\"American Football\", \"Animation\", \"Baseball\", \"Basketball\",\n",
    " \"Cooking and food recipes\", \"Golf\", \"Graffiti Art\", \"Hair Style\",\n",
    " \"Ice Hockey\", \"Judo\", \"Soccer\", \"Speeches and Lectures-Talks\",\n",
    " \"Swimming(in Pool)\", \"Tennis\", \"Underwater-Ocean life\",\n",
    " \"Volleyball\"]\n",
    "\n",
    "seq_size = 3600\n",
    "# dataset_path_frames_jenre_dir = dataset_path_frames_dir+\"/Cooking\"\n",
    "\n",
    "# os.makedirs(dataset_path_frames_jenre_dir)\n",
    "\n",
    "# dataset_path_video_jenre =dataset_path+\"/Cooking and food recipes\"\n",
    "# print(dataset_path)\n",
    "\n",
    "# filename = 'partial_dataset' # OR \"Dataset70_30\"( to run second time with 'Dataset80_20')\n",
    "\n",
    "# dataset_path =filename +\"/train\"     # os.path.join(filename, 'train')\n",
    "# dataset_path_frames_dir = filename+\"_frames\"\n",
    "\n",
    "\n",
    "# os.makedirs(dataset_path_frames_dir)\n",
    "# \"\"\"\n",
    "# test_path =filename +\"/test\"      # os.path.join(filename, 'train')\n",
    "# test_path_frames_dir = filename+\"/test_frames\"\n",
    "\n",
    "\n",
    "# os.makedirs(test_path_frames_dir)\n",
    "# \"\"\"\n",
    "# classes = [\"Animation\", \"Cooking and food recipes\"]\n",
    "\n",
    "\n",
    "# dataset_path_frames_jenre_dir = dataset_path_frames_dir+\"/Cooking\"\n",
    "\n",
    "# os.makedirs(dataset_path_frames_jenre_dir)\n",
    "\n",
    "# dataset_path_video_jenre =dataset_path+\"/Cooking and food recipes\"\n",
    "# print(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vital-oakland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problematic video: \n",
      "Dataset70_30/train/Animation/12.mp4\n",
      "num of frames: \n",
      "3196.0\n",
      "problematic video: \n",
      "Dataset70_30/train/Animation/5.mp4\n",
      "num of frames: \n",
      "3156.0\n",
      "problematic video: \n",
      "Dataset70_30/train/Cooking and food recipes/12.mp4\n",
      "num of frames: \n",
      "3597.0\n",
      "problematic video: \n",
      "Dataset70_30/train/Graffiti Art/11.mp4\n",
      "num of frames: \n",
      "3003.0\n",
      "problematic video: \n",
      "Dataset70_30/train/Hair Style/11.mp4\n",
      "num of frames: \n",
      "3339.0\n",
      "problematic video: \n",
      "Dataset70_30/train/Hair Style/5.mp4\n",
      "num of frames: \n",
      "3302.0\n",
      "problematic video: \n",
      "Dataset70_30/train/Hair Style/6.mp4\n",
      "num of frames: \n",
      "3027.0\n",
      "problematic video: \n",
      "Dataset70_30/train/Judo/0.mp4\n",
      "num of frames: \n",
      "3273.0\n",
      "problematic video: \n",
      "Dataset70_30/train/Judo/4.mp4\n",
      "num of frames: \n",
      "3002.0\n",
      "problematic video: \n",
      "Dataset70_30/train/Soccer/0.mp4\n",
      "num of frames: \n",
      "3250.0\n",
      "problematic video: \n",
      "Dataset70_30/train/Soccer/15.mp4\n",
      "num of frames: \n",
      "3241.0\n",
      "problematic video: \n",
      "Dataset70_30/train/Soccer/3.mp4\n",
      "num of frames: \n",
      "3154.0\n",
      "problematic video: \n",
      "Dataset70_30/train/Speeches and Lectures-Talks/11.mp4\n",
      "num of frames: \n",
      "3022.0\n",
      "problematic video: \n",
      "Dataset70_30/train/Speeches and Lectures-Talks/16.mp4\n",
      "num of frames: \n",
      "3341.0\n",
      "problematic video: \n",
      "Dataset70_30/train/Swimming(in Pool)/10.mp4\n",
      "num of frames: \n",
      "3336.0\n",
      "problematic video: \n",
      "Dataset70_30/train/Swimming(in Pool)/15.mp4\n",
      "num of frames: \n",
      "2153.0\n",
      "min num of frames per video: \n",
      "2153.0\n",
      "num of problematic videos: \n",
      "16\n"
     ]
    }
   ],
   "source": [
    "#creat frames from train:\n",
    "\n",
    "#data_dir = dataset_path\n",
    "#Desktop/folder to split dataset videogenre try/Dataset70_30/train/Animation\n",
    "count_problematic_vid = 0\n",
    "min_frames_per_vide=3600\n",
    "for jenre in classes:\n",
    "    #dataset_path_frames_jenre_dir = dataset_path_frames_dir+\"/\"+jenre\n",
    "\n",
    "    #os.makedirs(dataset_path_frames_jenre_dir)\n",
    "\n",
    "    dataset_path_video_jenre = dataset_path+\"/\"+jenre\n",
    "    #print(dataset_path)\n",
    "\n",
    "    listing = os.listdir(dataset_path_video_jenre)\n",
    "    #print(listing)\n",
    "    #listing = [inst for inst in listing if not inst.startswith(\".\")]\n",
    "    #print(listing)\n",
    "    \n",
    "    for file in listing:\n",
    "        #filenameeee= Path(file).stem\n",
    "        #print(filenameeee)\n",
    "        our_video = dataset_path_video_jenre +\"/\"+file\n",
    "        #print(our_video)\n",
    "        cap = cv2.VideoCapture(our_video)\n",
    "        #print(video.isOpened())\n",
    "        #framerate = video.get(5)\n",
    "        #os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + str(int(count)))\n",
    "        #filenamenotype= Path(file).stem\n",
    "        #print(filenamenotype)\n",
    "        #os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + filenamenotype)\n",
    "        \n",
    "        if (cap.isOpened()):\n",
    "            #frameId = video.get(1)\n",
    "            #success,image = video.read()        \n",
    "            numberofframes = cap.get(cv2.CAP_PROP_FRAME_COUNT)  # frames size in video\n",
    "            if(seq_size > numberofframes):\n",
    "                count_problematic_vid= count_problematic_vid+1\n",
    "                print(\"problematic video: \")\n",
    "                print(our_video)\n",
    "                print(\"num of frames: \")\n",
    "                print(numberofframes)\n",
    "                if( min_frames_per_vide > numberofframes):\n",
    "                    min_frames_per_vide=numberofframes\n",
    "                \n",
    "            \n",
    "\n",
    "        else:\n",
    "            print(\"cap could not open - in video:\\n\")\n",
    "            print(our_video)\n",
    "            exit()\n",
    "        cap.release()\n",
    "        #print('done')\n",
    "\n",
    "print(\"min num of frames per video: \")\n",
    "print(min_frames_per_vide)\n",
    "print(\"num of problematic videos: \")\n",
    "print(count_problematic_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tough-ebony",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat frames from train:\n",
    "\n",
    "#data_dir = dataset_path\n",
    "#Desktop/folder to split dataset videogenre try/Dataset70_30/train/Animation\n",
    "for jenre in classes:\n",
    "    dataset_path_frames_jenre_dir = dataset_path_frames_dir+\"/\"+jenre\n",
    "\n",
    "    os.makedirs(dataset_path_frames_jenre_dir)\n",
    "\n",
    "    dataset_path_video_jenre = dataset_path+\"/\"+jenre\n",
    "    #print(dataset_path)\n",
    "\n",
    "    listing = os.listdir(dataset_path_video_jenre)\n",
    "    #print(listing)\n",
    "    #listing = [inst for inst in listing if not inst.startswith(\".\")]\n",
    "    #print(listing)\n",
    "    seq_size = 30\n",
    "    for file in listing:\n",
    "        #filenameeee= Path(file).stem\n",
    "        #print(filenameeee)\n",
    "        our_video = dataset_path_video_jenre +\"/\"+file\n",
    "        #print(our_video)\n",
    "        cap = cv2.VideoCapture(our_video)\n",
    "        #print(video.isOpened())\n",
    "        #framerate = video.get(5)\n",
    "        #os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + str(int(count)))\n",
    "        filenamenotype= Path(file).stem\n",
    "        #print(filenamenotype)\n",
    "        os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + filenamenotype)\n",
    "        count = 0\n",
    "        if (cap.isOpened()):\n",
    "            #frameId = video.get(1)\n",
    "            #success,image = video.read()        \n",
    "            numberofframes = cap.get(cv2.CAP_PROP_FRAME_COUNT)  # frames size in video\n",
    "\n",
    "            jumping_frames = int(np.floor(numberofframes / seq_size) ) # need to take frame after this number of times\n",
    "            #frame_index_array = []\n",
    "            for i in range(0, seq_size):  # data size is the video size, check if start from 0 or 1 and end with size or size+1\n",
    "                # need to add index of frame  that devide with out reminder in self.seq_size from the specific video\n",
    "                #cap.set(cv2.CAP_PROP_POS_FRAMES,i*jumping_frames)\n",
    "                #changed to dumpy run over jumping frames, to prevent error accurs using cap.set in for loop\n",
    "                for j in range(0,jumping_frames-1):\n",
    "                    ret, frame = cap.read()\n",
    "                ret, frame = cap.read()\n",
    "                if ret == True:\n",
    "                    #resizearr = np.resize(frame, (3, 180, 220))\n",
    "                    #tensor[i] = torch.from_numpy(resizearr)\n",
    "                    filename = dataset_path_frames_jenre_dir + \"/video_\" + filenamenotype + \"/frame_\" + str(int(count)) + \".jpg\"\n",
    "                    #print(filename)\n",
    "                    cv2.imwrite(filename,frame)\n",
    "                    count = count+1\n",
    "                else:\n",
    "                    print(\"frame didnt extracted well or finished if shows uup try to delete this printing, in video:\\n\")\n",
    "                    print(our_video)\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            print(\"cap could not open - in video:\\n\")\n",
    "            print(our_video)\n",
    "            exit()\n",
    "        cap.release()\n",
    "        #print('done')\n",
    "\n",
    "#         os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + str(int(count)))\n",
    "#         if( image is not None ):\n",
    "#             image=cv2.resize(image,(224,224), interpolation = cv2.INTER_AREA)\n",
    "#         if (success is not True):\n",
    "#             break\n",
    "#         if (frameId % math.floor(framerate) == 0):\n",
    "#             filename = dataset_path_frames_jenre_dir + \"/video_\" + str(int(count)) + \"/image_\" + str(int(frameId / math.floor(framerate))+1) + \".jpg\"\n",
    "#             print(filename)\n",
    "#             cv2.imwrite(filename,image)\n",
    "#     video.release()\n",
    "#     print('done')\n",
    "#     count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "severe-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "filename = 'Dataset70_30' # OR \"Dataset70_30\"( to run second time with 'Dataset80_20')\n",
    "\n",
    "\n",
    "\n",
    "dataset_path =filename +\"/test\"      # os.path.join(filename, 'train')\n",
    "dataset_path_frames_dir = filename+\"/test_frames\"\n",
    "\n",
    "\n",
    "os.makedirs(dataset_path_frames_dir)\n",
    "\n",
    "# {\"American Football\", \"Animation\", \"Baseball\", \"Basketball\",\n",
    "#  \"Cooking and food recipes\", \"Golf\", \"Graffiti Art\", \"Hair Style\",\n",
    "#  \"Ice Hockey\", \"Judo\", \"Soccer\", \"Speeches and Lectures-Talks\",\n",
    "#  \"Swimming(in Pool)\", \"Tennis\", \"Underwater-Ocean life\",\n",
    "#  \"Volleyball\"}\n",
    "\n",
    "\n",
    "classes = [\"American Football\", \"Animation\", \"Baseball\", \"Basketball\",\n",
    " \"Cooking and food recipes\", \"Golf\", \"Graffiti Art\", \"Hair Style\",\n",
    " \"Ice Hockey\", \"Judo\", \"Soccer\", \"Speeches and Lectures-Talks\",\n",
    " \"Swimming(in Pool)\", \"Tennis\", \"Underwater-Ocean life\",\n",
    " \"Volleyball\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-aerospace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dynamic-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat frames from test:\n",
    "\n",
    "\n",
    "#data_dir = dataset_path\n",
    "#Desktop/folder to split dataset videogenre try/Dataset70_30/train/Animation\n",
    "for jenre in classes:\n",
    "    dataset_path_frames_jenre_dir = dataset_path_frames_dir+\"/\"+jenre\n",
    "\n",
    "    os.makedirs(dataset_path_frames_jenre_dir)\n",
    "\n",
    "    dataset_path_video_jenre = dataset_path+\"/\"+jenre\n",
    "    #print(dataset_path)\n",
    "\n",
    "    listing = os.listdir(dataset_path_video_jenre)\n",
    "    #print(listing)\n",
    "    #listing = [inst for inst in listing if not inst.startswith(\".\")]\n",
    "    #print(listing)\n",
    "    seq_size = 30\n",
    "    for file in listing:\n",
    "        #filenameeee= Path(file).stem\n",
    "        #print(filenameeee)\n",
    "        our_video = dataset_path_video_jenre +\"/\"+file\n",
    "        #print(our_video)\n",
    "        cap = cv2.VideoCapture(our_video)\n",
    "        #print(video.isOpened())\n",
    "        #framerate = video.get(5)\n",
    "        #os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + str(int(count)))\n",
    "        filenamenotype= Path(file).stem\n",
    "        #print(filenamenotype)\n",
    "        os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + filenamenotype)\n",
    "        count = 0\n",
    "        if (cap.isOpened()):\n",
    "            #frameId = video.get(1)\n",
    "            #success,image = video.read()        \n",
    "            numberofframes = cap.get(cv2.CAP_PROP_FRAME_COUNT)  # frames size in video\n",
    "\n",
    "            jumping_frames = int(np.floor(numberofframes / seq_size) ) # need to take frame after this number of times\n",
    "            #frame_index_array = []\n",
    "            for i in range(0, seq_size):  # data size is the video size, check if start from 0 or 1 and end with size or size+1\n",
    "                # need to add index of frame  that devide with out reminder in self.seq_size from the specific video\n",
    "                #cap.set(cv2.CAP_PROP_POS_FRAMES,i*jumping_frames)\n",
    "                #changed to dumpy run over jumping frames, to prevent error accurs using cap.set in for loop\n",
    "                for j in range(0,jumping_frames-1):\n",
    "                    ret, frame = cap.read()\n",
    "                ret, frame = cap.read()\n",
    "                if ret == True:\n",
    "                    #resizearr = np.resize(frame, (3, 180, 220))\n",
    "                    #tensor[i] = torch.from_numpy(resizearr)\n",
    "                    filename = dataset_path_frames_jenre_dir + \"/video_\" + filenamenotype + \"/frame_\" + str(int(count)) + \".jpg\"\n",
    "                    #print(filename)\n",
    "                    cv2.imwrite(filename,frame)\n",
    "                    count = count+1\n",
    "                else:\n",
    "                    print(\"frame didnt extracted well or finished if shows uup try to delete this printing, in video:\\n\")\n",
    "                    print(our_video)\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            print(\"cap could not open - in video:\\n\")\n",
    "            print(our_video)\n",
    "            exit()\n",
    "        cap.release()\n",
    "        #print('done')\n",
    "\n",
    "#         os.makedirs(dataset_path_frames_jenre_dir + \"/video_\" + str(int(count)))\n",
    "#         if( image is not None ):\n",
    "#             image=cv2.resize(image,(224,224), interpolation = cv2.INTER_AREA)\n",
    "#         if (success is not True):\n",
    "#             break\n",
    "#         if (frameId % math.floor(framerate) == 0):\n",
    "#             filename = dataset_path_frames_jenre_dir + \"/video_\" + str(int(count)) + \"/image_\" + str(int(frameId / math.floor(framerate))+1) + \".jpg\"\n",
    "#             print(filename)\n",
    "#             cv2.imwrite(filename,image)\n",
    "#     video.release()\n",
    "#     print('done')\n",
    "#     count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-harvest",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
